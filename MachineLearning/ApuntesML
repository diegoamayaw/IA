Labels: Variable objetivo.
Features: Variable de entrada que puede caracterizar la variable objetivo
Ejemplos pueden o no tener labels.
Entrenamiento para poder hacer una inferencia
Una regresión predice valores continuos, una clasificación tiene etiquetas definitivas como salida
Minimizar la pérdida (error cuadrado medio) de la regresión lineal en el mayor número de datos
Se pueden tener distintos pesos para diferentes variables.
Entrenamiento consiste en encontrar valores de pesos que minimicen el error del conjunto de datos de entrenamiento.

Para reducir la pérdida:
Gradientes(negativos) nos ayudan a ajustar parámetros para converger a la mínima pérdida.
Learning rate es un hiperparámetro que dice qué tan rápido pueden converger los pesos. Puede hacer que sea muy lento o incluso hacer diverger el modelo.
Mini-batch gradient descent (100-1000 examples) para ver cómo converge.
El objetivo es la generalización, hacer overfitting es malo porque obteniendo más datos, puede que no converga.
Usar un training set, otro es el test set, si le va bien en ambos, ya estuvo.
Los ejemplos son iid, son estacionarios (no cambian en el tiempo) y se obtienen de la misma distribución. (aunque no siempre aplican)

La causa principal del overfitting es hacer el modelo demasiado complicado.
Es bueno randomizar los datos antes de hacer los sets y depurar los datos. No entrenar en test data.
Los datos de prueba deben ser los suficientes para poder tener significancia estadística y ser representativos del modelo completo.

Se puede agregar un dataset que se llama validation set. Se separa del training, se ajustan los parámetros en el training y se prueban en el validation set, y hasta el final es cuando se ponen en el test set, cuando se tenga un modelo que trabaje mejor en el validation set.

Feature engineering: Extraer características de los datos crudos. Deben tener un valor lógico e intuitivo. Decidir si asignar números o convertirlo en booleano dependiendo del rango de los datos. Cuidar la estacionaridad de los datos con la semántica. Visualizar los datos (gráficas), debugear los datos (seccionar los datos) y actualizar los datos.

Usar características que sean comunes o se presenten varias veces.
Dejar fuera de los datos a los outliers. 
No usar valores arbitrarios (-1), si no se presenta un dato, crear una característica que diga si existe o no un dato.
Se pueden establecer rangos (punto flotante, 0-1) para ciertas características.
Para colas muy largas se puede hacer uso del escalamiento logarítmico o cortar el rango de datos arbitrariamente.
Se pueden agrupar datos numéricos en un valor de rango y asignarle una codificación

Se pueden hacer características sintéticas, como combinación de dos features y así poder discriminar mejor. Pero se tienen que cuidar la integridad y simpleza de los datos. La excesiva creación de características sintéticas, puede llevar a overfitting.

Regularización: Minimizar la peŕdida y la complejidad del sistema para no hacer overfitting en los datos de entrenamiento. Utilizar pesos pequeños. Se llama L2 regularización. Se puede medir la complejidad por medio de los pesos en los features o el número de features con pesos distintos de cero. Se hace haciendo la suma de los cuadrados de todos los pesos. La complejidad del modelo es multiplicada por una lambda, que indica el regularization rate. La regularización L2 busca normalizar los pesos a cero. Si Lambda es grande, el modelo será simple, pero con el riesgo de hacer underfitting, si es pequeño, habrá más complejidad y riesgo de hacer overfitting.


